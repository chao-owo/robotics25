#!/usr/bin/env python3
import math

import os
import sys
import rospy
import moveit_commander
import moveit_msgs.msg
import geometry_msgs.msg
from moveit_commander.conversions import pose_to_list
from std_msgs.msg import Bool
from math import sin, cos, pi
import rospkg 
import time
import speech_recognition as sr
import cv2
from datetime import datetime
import numpy as np
from numpy import sin, cos
from std_msgs.msg import Float64MultiArray

initial_offset = [0, -math.pi/2, math.pi/2, 0]
delay_time = 0.0045

color_ranges = {
    'red': [
        ([0, 50, 20], [10, 255, 255]),    
        ([160, 50, 20], [180, 255, 255])   
    ],
    'green': [
        ([35, 40, 20], [85, 255, 255])
    ],
    'blue': [
        ([90, 50, 20], [150, 255, 255])
    ]
}

def capture_image_after_delay(save_dir="~/Robotics/photos", delay_sec=1):

    save_dir = os.path.expanduser(save_dir)
    os.makedirs(save_dir, exist_ok=True)

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ")
        return None

    print(f"â³ ç­‰å¾… {delay_sec} ç§’å¾Œæ‹ç…§...")
    time.sleep(delay_sec)

    ret, frame = cap.read()
    cap.release()

    if not ret:
        print("âŒ æ‹ç…§å¤±æ•—")
        return None

    # å„²å­˜å½±åƒ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = os.path.join(save_dir, f"{timestamp}.jpg")
    cv2.imwrite(filename, frame)
    print(f"âœ… å½±åƒå·²å„²å­˜ï¼š{filename}")
    return filename

def detect_color_positions(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    positions = []

    for color, ranges in color_ranges.items():
        mask = None
        for lower, upper in ranges:
            lower_np = np.array(lower)
            upper_np = np.array(upper)
            new_mask = cv2.inRange(hsv, lower_np, upper_np)
            mask = new_mask if mask is None else cv2.bitwise_or(mask, new_mask)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest = max(contours, key=cv2.contourArea)
            M = cv2.moments(largest)
            if M['m00'] != 0:
                cx = int(M['m10'] / M['m00'])
                positions.append((cx, color_to_size[color]))

    positions.sort()  # æŒ‰ç…§ x åº§æ¨™å¾å·¦åˆ°å³
    return [size for _, size in positions]

def assign_towers_by_vision(image_path='photos/123.jpg'):
    image = cv2.imread(image_path)
    order = detect_color_positions(image)  # e.g. [3, 1, 2]

    if len(order) != 3:
        raise ValueError("âŒ ç„¡æ³•æ­£ç¢ºè¾¨è­˜ä¸‰å€‹å¡”çš„ä½ç½®")

    size_to_peg = {}
    for peg, size in zip(['A', 'B', 'C'], order):
        size_to_peg[size] = peg

    print(f"ğŸ“¸ å½±åƒè¾¨è­˜å¡”é †åº: {order}")
    print(f"ğŸ—ºï¸ Tower å¤§å°å°æ‡‰ Peg: {size_to_peg}")
    return size_to_peg

 def spawn_hanoi_towers(path_object, vo_list):
    '''Spawn the three Hanoi towers in the scene with positions determined by vo_list'''
    base_positions = [
        (p_Tower_x, p_Tower_y, 0.0),    # Position 0 -> top
        (p_Tower_x, 0.0, 0.0),          # Position 1 -> middle  
        (p_Tower_x, -p_Tower_y, 0.0)   # Position 2 -> bottom
    ]

    mesh_names = ['A', 'B', 'C']
    
    # Initialize tower_disks dictionary
    global tower_disks
    tower_disks = {'A': [], 'B': [], 'C': []}

    # Update tower_coords to match the new positions
    global tower_coords
    tower_coords = {}
    
    # Create position mapping: tower_name -> position
    tower_positions = {}
    for position_idx, tower_id in enumerate(vo_list):
        tower_name = mesh_names[tower_id - 1]  
        tower_positions[tower_name] = base_positions[position_idx]
        tower_coords[tower_name] = (base_positions[position_idx][0], base_positions[position_idx][1])

    # Spawn towers at their assigned positions
    for i, tower_name in enumerate(mesh_names):
        x, y, z = tower_positions[tower_name]
        
        mesh_pose = geometry_msgs.msg.PoseStamped()
        mesh_pose.header.frame_id = 'world'
        mesh_pose.pose.position.x = x
        mesh_pose.pose.position.y = y
        mesh_pose.pose.position.z = z

        path_object.add_mesh(tower_name, mesh_pose, MESH_FILE_PATH[i], (.00095, .00095, .00095))
        print(f"Added {tower_name} at position ({x}, {y}, {z})")

def save_voice_command(file_path="/home/cynthia/Robotics/voice_command.txt", language="zh-TW"):
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()

    print("ğŸ¤ ç­‰å¾…èªéŸ³è¼¸å…¥ä¸­ï¼ˆå°‡æ–¼ 1 ç§’å¾Œé–‹å§‹éŒ„éŸ³ï¼‰...")
    time.sleep(1)

    with microphone as source:
        recognizer.adjust_for_ambient_noise(source)
        print("ğŸ“¢ è«‹é–‹å§‹èªªè©±...")
        audio = recognizer.listen(source)
        print("ğŸ§  è¾¨è­˜ä¸­...")

    try:
        recognized_text = recognizer.recognize_google(audio, language=language)
        print(f"âœ… èªè­˜çµæœï¼š{recognized_text}")

        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(recognized_text + "\n")

        print(f"ğŸ’¾ æˆåŠŸå¯«å…¥ï¼š{file_path}")
        return recognized_text

    except sr.UnknownValueError:
        print("âŒ ç„¡æ³•è¾¨è­˜èªéŸ³")
        return None
    except sr.RequestError as e:
        print(f"âŒ èªéŸ³è¾¨è­˜è«‹æ±‚å¤±æ•—: {e}")
        return None

def read_voice_commands(path="/home/cynthia/Robotics/voice_command.txt"):
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip()]
    except Exception as e:
        print(f"âŒ èªéŸ³æŒ‡ä»¤è®€å–å¤±æ•—: {e}")
        return []

def parse_instruction(instruction):
    """
    æ”¯æ´æ ¼å¼ï¼š
    - å¾[ä½ç½®]ç§»åˆ°[ä½ç½®]
    - å¾[ä½ç½®]ç§»å‹•åˆ°[ä½ç½®]
    - å¾[ä½ç½®]æ¬åˆ°[ä½ç½®]
    - å¾[ä½ç½®]åˆ°[ä½ç½®]
    - åˆ°[ä½ç½®]
    - ç§»åˆ°[ä½ç½®]
    - æ¬åˆ°[ä½ç½®]
    - çµ‚é»ä½ç½®ç‚º[ä½ç½®]
    - ä½ç½®å¯ç”¨ a/A/å·¦ã€b/B/ä¸­ã€c/C/å³ è¡¨ç¤º
    å›å‚³ tuple: (src, dst)ï¼Œè‹¥åªæœ‰çµ‚é»ï¼Œsrc å›å‚³ None
    """
    import re

    pos_map = {
        'a': 'A', 'A': 'A', 'å·¦': 'A', 'å·¦é‚Š': 'A',
        'b': 'B', 'B': 'B', 'ä¸­': 'B', 'ä¸­é–“': 'B',
        'c': 'C', 'C': 'C', 'å³': 'C', 'å³é‚Š': 'C',
    }

    instr = instruction.strip().replace(" ", "")

    # é›™ä½ç½®å½¢å¼
    patterns = [
        r"å¾(.*?)æ¬åˆ°(.*?)",
        r"å¾(.*?)ç§»å‹•åˆ°(.*?)",
        r"å¾(.*?)ç§»åˆ°(.*?)",
        r"å¾(.*?)åˆ°(.*?)",
    ]

    for pat in patterns:
        m = re.match(pat, instr)
        if m:
            src = pos_map.get(m.group(1), None)
            dst = pos_map.get(m.group(2), None)
            if src and dst:
                return src, dst
            else:
                raise ValueError(f"âŒ ç„¡æ³•è§£æä½ç½®ï¼š{m.group(1)} æˆ– {m.group(2)}")

    # å–®ä½ç½®å½¢å¼ï¼ˆåªæŒ‡å®šç›®æ¨™ï¼‰
    single_patterns = [
        r"åˆ°(.*?)",
        r"ç§»åˆ°(.*?)",
        r"æ¬åˆ°(.*?)",
        r"çµ‚é»ä½ç½®ç‚º(.*?)"
    ]

    for pat in single_patterns:
        m = re.match(pat, instr)
        if m:
            dst = pos_map.get(m.group(1), None)
            if dst:
                return None, dst
            else:
                raise ValueError(f"âŒ ç„¡æ³•è§£æç›®æ¨™ä½ç½®ï¼š{m.group(1)}")

    raise ValueError(f"âŒ ç„¡æ³•è§£æèªéŸ³æŒ‡ä»¤æ ¼å¼ï¼š{instruction}")


def apply_initial_offset(angles):
    for i in range(4):
        angles[i] = angles[i] - initial_offset[i]
    return angles

def send_joint_angles_from_file(file_path, delay=0.05):
    rospy.init_node('txt_to_real_arm_publisher', anonymous=True)
    pub = rospy.Publisher('/real_robot_arm_joint', Float64MultiArray, queue_size=10)
    rospy.sleep(1.0)

    with open(file_path, 'r') as f:
        lines = f.readlines()

    rospy.loginfo(f"ğŸ“„ é–‹å§‹å‚³é€ {len(lines)} è¡Œé—œç¯€è§’åº¦")

    for i, line in enumerate(lines):
        try:
            angles = list(map(float, line.strip().split(',')))
            if len(angles) < 5:
                rospy.logwarn(f"âš ï¸ ç¬¬ {i+1} è¡Œè³‡æ–™ä¸è¶³ï¼Œç•¥é")
                continue
            
            
            angles = apply_initial_offset(angles)
            msg = Float64MultiArray(data=angles)
            pub.publish(msg)
            rospy.loginfo(f"ğŸ“¤ ç¬¬ {i+1} é»: {['%.3f' % a for a in angles]}")
            rospy.sleep(delay)
        except ValueError:
            rospy.logwarn(f"âš ï¸ ç¬¬ {i+1} è¡Œæ ¼å¼éŒ¯èª¤ï¼Œç•¥é")

    rospy.loginfo("âœ… å‚³é€å®Œç•¢")

def main():
    
    try:
        # Initialize voice command subscriber
        # rospy.Subscriber('/voice_case_cmd', String, voice_callback)
        image_path = capture_image_after_delay()
        if image_path:
            image = cv2.imread(image_path)
            vision_order = detect_color_positions(image)
            vo = vision_order[::-1]
            print(f"ğŸ“· Vision è¾¨è­˜é †åºç‚º: {vo}")
        spawn_hanoi_towers(path_object,vo)

        voice_result = save_voice_command()
    
        if voice_result is None:
            print("âŒ ç„¡æ³•ç²å¾—èªéŸ³è¼¸å…¥")
            return
        
        # è§£æèªéŸ³æŒ‡ä»¤ä»¥ç²å¾—æ–¹å‘
        try:
            if "å·¦" in voice_result:
                voice_direction = "å·¦"
            elif "å³" in voice_result:
                voice_direction = "å³"
            elif "ä¸­" in voice_result:
                voice_direction = "ä¸­"
        except:
            # å¦‚æœè§£æå¤±æ•—ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹èªéŸ³çµæœ
            voice_direction = voice_result
        
        sys.stderr.write("Finish initializing. Press Enter to continue..."); input()    

        try:
            if vo == [3,2,1]:
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/ini_11_interpolation.txt', delay=delay_time)
            elif vo == [2,3,1]:
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/ini_12_interpolation.txt', delay=delay_time)
            elif vo == [2,1,3]:
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/ini_31_interpolation.txt', delay=delay_time)
            elif vo == [3,1,2]:
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/ini_32_interpolation.txt', delay=delay_time)
            elif vo == [1,2,3]:
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/ini_51_interpolation.txt', delay=delay_time)
            elif vo == [1,3,2]:
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/ini_52_interpolation.txt', delay=delay_time)
        except rospy.ROSInterruptException:
            print("send angles error")

        index_of_1 = vo.index(1)

        if index_of_1 == 2:
            if voice_direction == 'ä¸­':
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/case_1.txt', delay=delay_time)
            elif voice_direction == 'å³':
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/case_2.txt', delay=delay_time)
            elif voice_direction =='å·¦':
                print("~finished~")
            else:
                print(f"index_of_1=0 æ™‚ï¼Œä¸æ”¯æ´èªéŸ³æŒ‡ä»¤: {voice_direction}")
        
        elif index_of_1 == 1:
            if voice_direction == 'å·¦':
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/case_3.txt', delay=delay_time)
            elif voice_direction == 'å³':
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/case_4.txt', delay=delay_time)
            elif voice_direction =='ä¸­':
                print("~finished~")
            else:
                print(f"index_of_1=1 æ™‚ï¼Œä¸æ”¯æ´èªéŸ³æŒ‡ä»¤: {voice_direction}")
        
        elif index_of_1 == 0:
            if voice_direction == 'å·¦':
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/case_5.txt', delay=delay_time)
            elif voice_direction == 'ä¸­':
                send_joint_angles_from_file('/home/cynthia/Robotics/trajectory/case_6.txt', delay=delay_time)
            elif voice_direction =='å³':
                print("~finished~")
            else:
                print(f"index_of_1=2 æ™‚ï¼Œä¸æ”¯æ´èªéŸ³æŒ‡ä»¤: {voice_direction}")
        
        else:
            print(f"ä¸æ”¯æ´çš„ index_of_1 å€¼: {index_of_1}")

    except rospy.ROSInterruptException:
        return
    except KeyboardInterrupt:
        return

if __name__ == '__main__':
    main()